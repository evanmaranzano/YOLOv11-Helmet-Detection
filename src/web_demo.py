import streamlit as st
from ultralytics import YOLO
import cv2
import tempfile
import numpy as np
from PIL import Image
from utils import load_config

# Load config
try:
    cfg = load_config()
    default_model = cfg['weights']
except:
    default_model = "yolo11s.pt"

# Config
st.set_page_config(layout="wide", page_title="å·¥åœ°å®‰å…¨å¸½æ£€æµ‹ç³»ç»Ÿ", page_icon="ğŸ‘·")

def main():
    st.title("ğŸ‘· å·¥åœ°å®‰å…¨å¸½ä½©æˆ´æ£€æµ‹ç³»ç»Ÿ")
    st.sidebar.header("é…ç½® (Settings)")

    # Model Selection
    model_path = st.sidebar.text_input("æ¨¡å‹è·¯å¾„ (Model Path)", default_model)
    conf_threshold = st.sidebar.slider("ç½®ä¿¡åº¦é˜ˆå€¼ (Confidence)", 0.0, 1.0, 0.25)
    
    try:
        model = YOLO(model_path)
        st.sidebar.success("æ¨¡å‹åŠ è½½æˆåŠŸ!")
    except Exception as e:
        st.sidebar.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return

    # Input Mode
    mode = st.sidebar.selectbox("æ£€æµ‹æ¨¡å¼ (Mode)", ["å›¾ç‰‡æ£€æµ‹ (Image)", "è§†é¢‘æ£€æµ‹ (Video)", "æ‘„åƒå¤´å®æ—¶ (Webcam)"])

    if mode == "å›¾ç‰‡æ£€æµ‹ (Image)":
        uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=['jpg', 'png', 'jpeg'])
        if uploaded_file:
            image = Image.open(uploaded_file)
            st.image(image, caption="åŸå§‹å›¾ç‰‡", use_container_width=True)
            
            if st.button("å¼€å§‹æ£€æµ‹"):
                # Inference
                res = model.predict(image, conf=conf_threshold)
                res_plotted = res[0].plot()
                st.image(res_plotted, caption="æ£€æµ‹ç»“æœ", channels="BGR", use_container_width=True)

    elif mode == "è§†é¢‘æ£€æµ‹ (Video)":
        uploaded_file = st.file_uploader("ä¸Šä¼ è§†é¢‘", type=['mp4', 'avi'])
        if uploaded_file:
            tfile = tempfile.NamedTemporaryFile(delete=False) 
            tfile.write(uploaded_file.read())
            
            cap = cv2.VideoCapture(tfile.name)
            stframe = st.empty()
            
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                
                # Inference
                res = model.predict(frame, conf=conf_threshold)
                res_plotted = res[0].plot()
                
                stframe.image(res_plotted, channels="BGR", use_container_width=True)
            cap.release()

    elif mode == "æ‘„åƒå¤´å®æ—¶ (Webcam)":
        st.warning("Webcam mode works best locally. Ensure camera access.")
        run = st.checkbox('å¼€å¯æ‘„åƒå¤´')
        FRAME_WINDOW = st.image([])
        camera = cv2.VideoCapture(0)

        while run:
            _, frame = camera.read()
            if frame is None:
                break
            
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = model(frame, conf=conf_threshold)
            annotated_frame = results[0].plot()
            
            FRAME_WINDOW.image(annotated_frame, channels="BGR")
        else:
            camera.release()

if __name__ == "__main__":
    main()
